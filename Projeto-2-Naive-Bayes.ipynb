{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 19/Set até às 23:59.<br />\n",
    "Grupo: 2 ou 3 pessoas - grupos com 3 pessoas terá uma rubrica diferenciada.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO gravar a key do professor no arquivo**\n",
    "\n",
    "\n",
    "### Entrega Intermediária: Check 1 - APS 2\n",
    "\n",
    "Até o dia 10/Set às 23:59, xlsx deve estar no Github com as seguintes evidências: \n",
    "\n",
    "  * Produto escolhido.\n",
    "  * Arquivo Excel contendo a base de treinamento e a base de testes já classificadas.\n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Parte I - Adquirindo a Base de Dados\n",
    "\n",
    "Acessar o notebook **Projeto-2-Planilha** para realizar a coleta dos dados. O grupo deve classificar os dados coletados manualmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from math import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Parte II - Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Não se esqueça de implementar o Laplace Smoothing (https://en.wikipedia.org/wiki/Laplace_smoothing).\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n",
    "Escreva o seu código abaixo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import re\n",
    "lista = []\n",
    "\n",
    "for i in civic.Treinamento:\n",
    "    i.replace(\":\", \" \")\n",
    "    i.replace(\".\", \" \")\n",
    "    i.replace(\";\", \" \")\n",
    "    i.replace(\"?\", \" \")\n",
    "    i.replace(\"/\", \" \")\n",
    "    i.replace(\"\\n\", \" \")\n",
    "    i.replace(\"''\", \" \")\n",
    "    i.replace(\",\", \" \")\n",
    "    i.replace(\"..\", \" \")\n",
    "    i.replace(\"...\", \" \")\n",
    "    lista.append(re.split(' #|@', i))\n",
    "    \n",
    "print(lista)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import re\n",
    "lista = []\n",
    "\n",
    "for tweet in civic.Treinamento:\n",
    "    for palavra in tweet:\n",
    "        for letra in palavra:\n",
    "            if letra == \"@\" or letra == \"#\":\n",
    "                palavra = \"\"\n",
    "    print (\"\\n\" + tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmve(excel, sht):\n",
    "    \n",
    "    nome = pd.read_excel(excel, sheet_name = sht).loc[:, [sht,'Relevância']]\n",
    "    \n",
    "    if sht == \"Treinamento\": \n",
    "\n",
    "        lista_1 = []\n",
    "        lista_2 = []\n",
    "        lista_3 = []\n",
    "        lista_4 = []\n",
    "        lista_5 = []\n",
    "\n",
    "        dataFrameli = [\n",
    "        lista_1,\n",
    "        lista_2,\n",
    "        lista_3,\n",
    "        lista_4,\n",
    "        lista_5\n",
    "        ]\n",
    "\n",
    "        lista_twt = []\n",
    "\n",
    "        for i in range(0, len(dataFrameli)):\n",
    "            for tweet in nome[nome[\"Relevância\"] == i + 1][sht]:\n",
    "                msg = tweet.lower().replace(\".\", \"\").replace(\"#\", \" #\").replace(\"||\", \"\").replace(\"|\", \"\").replace(\"[\", \"\").replace(\"/\", \"\").replace(\"+\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\"-\", \"\").replace(\"!\", \" ! \").replace(\"?\", \" ? \").replace(\":\", \"\").replace(\",\", \"\").replace(\";\", \"\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"..\", \"\").replace(\"…\", \"\").replace(\"\\n\", \"\").replace('\"', \"\").replace(\"—\", \"\").replace(\"//\", \"\")\n",
    "                for palavra in msg.split(\" \"):\n",
    "                    if palavra != \"\":\n",
    "                        lista_twt.append(palavra)\n",
    "\n",
    "                dataFrameli[i].append(lista_twt)\n",
    "                lista_twt = []\n",
    "\n",
    "        li_rm = []\n",
    "        for lista in range(0, len(dataFrameli)):\n",
    "            for frase in dataFrameli[lista]:\n",
    "                for palavra in frase:\n",
    "                    if \"https\" in palavra or \"@\" in palavra:\n",
    "                        li_rm.append(palavra)\n",
    "\n",
    "                for i in li_rm:\n",
    "                    frase.remove(i)\n",
    "\n",
    "                li_rm = []   \n",
    "    \n",
    "    elif sht == \"Teste\":\n",
    "        \n",
    "        dataFrameli = []\n",
    "        lista_twt = []\n",
    "        \n",
    "        for tweet in nome[sht]:\n",
    "            msg = tweet.lower().replace(\".\", \"\").replace(\"#\", \" #\").replace(\"||\", \"\").replace(\"|\", \"\").replace(\"[\", \"\").replace(\"/\", \"\").replace(\"+\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\"-\", \"\").replace(\"!\", \" ! \").replace(\"?\", \" ? \").replace(\":\", \"\").replace(\",\", \"\").replace(\";\", \"\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"..\", \"\").replace(\"…\", \"\").replace(\"\\n\", \"\").replace('\"', \"\").replace(\"—\", \"\").replace(\"//\", \"\")\n",
    "            for palavra in msg.split(\" \"):\n",
    "                if palavra != \"\":\n",
    "                    lista_twt.append(palavra)\n",
    "\n",
    "            dataFrameli.append(lista_twt)\n",
    "            lista_twt = []\n",
    "            \n",
    "        li_rm = []\n",
    "        for frase in dataFrameli:\n",
    "            for palavra in frase:\n",
    "                if \"https\" in palavra or \"@\" in palavra:\n",
    "                    li_rm.append(palavra)\n",
    "\n",
    "            for i in li_rm:\n",
    "                frase.remove(i)\n",
    "\n",
    "            li_rm = []  \n",
    "    \n",
    "    return dataFrameli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = rmve('tweets_civic_201809051726.xlsx', \"Treinamento\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Obrigatório para grupos de 3 alunos:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções secundárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soma_data(data):\n",
    "    \n",
    "    contador = 0\n",
    "    \n",
    "    for tweet in data.Treinamento:\n",
    "        contador += 1\n",
    "    \n",
    "    return contador\n",
    "\n",
    "def cont_pal(lista):\n",
    "    \n",
    "    lista2 = []\n",
    "    \n",
    "    for listinhas in lista:\n",
    "        for frases in listinhas:\n",
    "            for palavras in frases:\n",
    "                if palavras not in lista2:\n",
    "                    lista2.append(palavras)\n",
    "    cont  = 0\n",
    "\n",
    "    for i in lista2:\n",
    "        cont += 1 \n",
    "    \n",
    "    return cont\n",
    "\n",
    "def cont_pal_2(dataFrame, li):\n",
    "\n",
    "    tamanho  = 0\n",
    "    li_rt  = []\n",
    "    \n",
    "    for i in dataFrame:\n",
    "        if i != li:\n",
    "            for frase in i:\n",
    "                for pal in frase:\n",
    "                    tamanho += 1\n",
    "    \n",
    "    li_rt.append(tamanho)\n",
    "    tamanho = 0\n",
    "    \n",
    "    for frase in li:\n",
    "        for palavra in frase:\n",
    "            tamanho += 1\n",
    "            \n",
    "    li_rt.append(tamanho)\n",
    "    \n",
    "    return li_rt\n",
    "\n",
    "\n",
    "def acha_valor(palavra, lenght, p, tamanho_sm_rp):\n",
    "    valor  = 0\n",
    "    \n",
    "    for pal in p:\n",
    "        if palavra == pal:\n",
    "            valor = p[pal]\n",
    "    \n",
    "    if valor == 0:\n",
    "        valor  = 1/(tamanho_sm_rp + lenght[1])\n",
    "    \n",
    "    return valor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções principais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pb_rel(data):\n",
    "    \n",
    "    dt = pd.read_excel(data).loc[:, ['Treinamento','Relevância']].sort_values('Relevância', ascending=False)\n",
    "    \n",
    "    dici_rel = {}\n",
    "    \n",
    "    for i in range(5):\n",
    "        \n",
    "        nd = dt[dt[\"Relevância\"] == i + 1]\n",
    "        dici_rel[\"Ser \" + str(i)] = len(nd)/soma_data(dt)\n",
    "        dici_rel[\"Não ser \" + str(i)] = (soma_data(dt) - len(nd))/soma_data(dt)\n",
    "        \n",
    "    return dici_rel\n",
    "\n",
    "def pr_pl(dataframe, lista, palavra_total, cond):\n",
    "    \n",
    "    dici_p = {}\n",
    "    \n",
    "    if cond == \"ser\":\n",
    "    \n",
    "        contador = 0\n",
    "        \n",
    "        for frase in lista:\n",
    "            for palavra in frase:\n",
    "                for frase2 in lista:\n",
    "                    for comparador in frase2:\n",
    "                        \n",
    "                        if palavra == comparador:\n",
    "                            contador += 1\n",
    "                            \n",
    "                dici_p[palavra] = (contador + 1)/(cont_pal_2(dataframe, lista)[1] + palavra_total)\n",
    "                contador = 0\n",
    "    \n",
    "    elif cond == \"nao ser\":\n",
    "\n",
    "        contador = 0\n",
    "        \n",
    "        for frases in lista:\n",
    "        \n",
    "            for palavras in frases:\n",
    "\n",
    "                for i in dataframe:\n",
    "\n",
    "                    if i != lista:\n",
    "                        for frase in i:\n",
    "                            for comparador in frase:\n",
    "\n",
    "                                if palavras == comparador:\n",
    "                                    contador += 1\n",
    "\n",
    "                dici_p[palavras] = (contador + 1)/(cont_pal_2(dataframe, lista)[0] + palavra_total)            \n",
    "                contador = 0\n",
    "    \n",
    "    return dici_p\n",
    "\n",
    "def bayes(dt, teste_limpo, rel, p, p2, p3, p4, p5, tm1, tm2, tm3, tm4, tm5):\n",
    "    \n",
    "    l_pbr = []\n",
    "    dici_pbr = {}\n",
    "    \n",
    "    ps1 = 1\n",
    "    ps2 = 1\n",
    "    ps3 = 1\n",
    "    ps4 = 1\n",
    "    ps5 = 1\n",
    "    \n",
    "    for frases in range(len(teste_limpo)):\n",
    "        for palavras in teste_limpo[frases]:                \n",
    "            ps1 *= acha_valor(palavras, tm1, palavras_1, tamanho_sm_rp)\n",
    "            ps2 *= acha_valor(palavras, tm2, palavras_2, tamanho_sm_rp)\n",
    "            ps3 *= acha_valor(palavras, tm3, palavras_3, tamanho_sm_rp)\n",
    "            ps4 *= acha_valor(palavras, tm4, palavras_4, tamanho_sm_rp)\n",
    "            ps5 *= acha_valor(palavras, tm5, palavras_5, tamanho_sm_rp)\n",
    "            \n",
    "        ps1 *= rel[\"Ser 0\"]\n",
    "        ps2 *= rel[\"Ser 1\"]\n",
    "        ps3 *= rel[\"Ser 2\"]\n",
    "        ps4 *= rel[\"Ser 3\"]\n",
    "        ps5 *= rel[\"Ser 4\"]\n",
    "\n",
    "        l_pbr.append(ps1)\n",
    "        l_pbr.append(ps2)\n",
    "        l_pbr.append(ps3)\n",
    "        l_pbr.append(ps4)\n",
    "        l_pbr.append(ps5)\n",
    "            \n",
    "        if ps1 == max(l_pbr):\n",
    "            dici_pbr[dt[\"Teste\"][frases]] = 1 \n",
    "            \n",
    "        elif ps2 == max(l_pbr):\n",
    "            dici_pbr[dt[\"Teste\"][frases]] = 2\n",
    "            \n",
    "        elif ps3 == max(l_pbr):\n",
    "            dici_pbr[dt[\"Teste\"][frases]] = 3 \n",
    "            \n",
    "        elif ps4 == max(l_pbr):\n",
    "            dici_pbr[dt[\"Teste\"][frases]] = 4 \n",
    "            \n",
    "        elif ps5 == max(l_pbr):\n",
    "            dici_pbr[dt[\"Teste\"][frases]] = 5\n",
    "                     \n",
    "        l_pbr = []\n",
    "            \n",
    "        ps1 = 1\n",
    "        ps2 = 1\n",
    "        ps3 = 1\n",
    "        ps4 = 1\n",
    "        ps5 = 1\n",
    "            \n",
    "    return dici_pbr\n",
    "\n",
    "def comparativo(dici, data):\n",
    "    \n",
    "    posn = 0\n",
    "    faln = 0\n",
    "    posmr = 0\n",
    "    falmr = 0\n",
    "    posr = 0\n",
    "    falr = 0\n",
    "    posi = 0\n",
    "    fali = 0\n",
    "    posmi = 0\n",
    "    falmi = 0\n",
    "    falir = 0\n",
    "    \n",
    "    dici_rt = {}\n",
    "    \n",
    "    for i in dici:\n",
    "        for com in data[\"Teste\"]:\n",
    "            if i == com:\n",
    "                if dici[i] == int(data.loc[data['Teste'] == com]['Relevância'][data.loc[data['Teste'] == com]['Relevância'].index[0]]):\n",
    "                    \n",
    "                    if dici[i] == 1:\n",
    "                        posmr += 1\n",
    "                    \n",
    "                    if dici[i] == 2:\n",
    "                        posr += 1\n",
    "                    \n",
    "                    if dici[i] == 3:\n",
    "                        posn += 1\n",
    "                    \n",
    "                    if dici[i] == 4:\n",
    "                        posi += 1\n",
    "                    \n",
    "                    if dici[i] == 5:\n",
    "                        posmi += 1\n",
    "                \n",
    "                else:\n",
    "\n",
    "                    if dici[i] == 1:\n",
    "                        falmr += 1\n",
    "\n",
    "                    if dici[i] == 2:\n",
    "                        falr += 1\n",
    "\n",
    "                    if dici[i] == 3:\n",
    "                        faln += 1\n",
    "\n",
    "                    if dici[i] == 4:\n",
    "                        fali += 1\n",
    "\n",
    "                    if dici[i] == 5:\n",
    "                        falmi += 1\n",
    "               \n",
    "    dici_rt[\"Positivos\"] = [posmr/200*100, posr/200*100, posn/200*100, posi/200*100, posmi/200*100, posmr/200*100 + posr/200*100, posmr/200*100 + posr/200*100 + posn/200*100 + posi/200*100 + posmi/200*100]\n",
    "    dici_rt[\"Falsos\"] = [falmr/200*100, falr/200*100, faln/200*100, fali/200*100, falmi/200*100, falmr/200*100 + falr/200*100, falmr/200*100 + falr/200*100 + faln/200*100 + fali/200*100 + falmi/200*100]\n",
    "    \n",
    "    return  dici_rt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "relcao_1 = pb_rel('tweets_civic_201809051726.xlsx')\n",
    "tamanho_sm_rp = cont_pal(data)\n",
    "tm1 = cont_pal_2(data, data[0])\n",
    "tm2 = cont_pal_2(data, data[1])\n",
    "tm3 = cont_pal_2(data, data[2])\n",
    "tm4 = cont_pal_2(data, data[3])\n",
    "tm5 = cont_pal_2(data, data[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "palavras_1 = pr_pl(data, data[0], cont_pal(data), \"ser\")\n",
    "palavras_2 = pr_pl(data, data[1], cont_pal(data), \"ser\")\n",
    "palavras_3 = pr_pl(data, data[2], cont_pal(data), \"ser\")\n",
    "palavras_4 = pr_pl(data, data[3], cont_pal(data), \"ser\")\n",
    "palavras_5 = pr_pl(data, data[4], cont_pal(data), \"ser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tst = pd.read_excel('tweets_civic_201809051726.xlsx', sheet_name = \"Teste\").loc[:, [\"Teste\",'Relevância']]\n",
    "tst2 = rmve('tweets_civic_201809051726.xlsx', \"Teste\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bayes_dici = bayes(tst, tst2, relcao_1, palavras_1, palavras_2, palavras_3, palavras_4, palavras_5, tm1, tm2, tm3, tm4, tm5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnl = comparativo(bayes_dici, tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross = pd.DataFrame.from_dict(fnl).transpose().rename(columns = {0: \"Muito Relevante (%)\", 1: \"Relevante (%)\", 2: \"Neutro (%)\", 3: \"Irrelevante (%)\", 4: \"Muito Irrelevante (%)\", 5: \"Relevantes (%)\", 6: \"Total (%)\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclusão.<br /> \n",
    "Faça um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como são tratadas as mensagens com dupla negação e sarcasmo.<br />\n",
    "Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Muito Relevante (%)</th>\n",
       "      <th>Relevante (%)</th>\n",
       "      <th>Neutro (%)</th>\n",
       "      <th>Irrelevante (%)</th>\n",
       "      <th>Muito Irrelevante (%)</th>\n",
       "      <th>Relevantes (%)</th>\n",
       "      <th>Total (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Falsos</th>\n",
       "      <td>1.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positivos</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Muito Relevante (%)  Relevante (%)  Neutro (%)  Irrelevante (%)  \\\n",
       "Falsos                     1.5            9.0        16.5             17.0   \n",
       "Positivos                  0.0           10.5        25.0             15.5   \n",
       "\n",
       "           Muito Irrelevante (%)  Relevantes (%)  Total (%)  \n",
       "Falsos                       1.0            10.5       45.0  \n",
       "Positivos                    4.0            10.5       55.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao plotar a tabela crosstab acima, conclui-se que o classificador teve uma porcentagem de acerto de 55% total dos tweets, enquanto seu indice de erro foi de 45%. Conclue-se que tais porcentagens estão muito próximas, o que não foi o esperado para o classificador. Ao analizar os possiveis motivos para o ocorrido, notou-se que foi utilizada uma base de apenas 300 tweets para treinar o classificador, o que acaba não dando espaço para um grande numero de tweets dentro de uma categoria (apenas 11 foram classificados como muito relevante). Por conta disso, o classificador acaba por não cumprir com o esperado, já que aparecem poucas palavras e repetições para o mesmo calcular as probabilidades. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em contrapartida, nota-se que quando o classificador erra, o mesmo na maioria das vezes não classifica um objeto irrelevante como muito relevante, mas sim algo próximo de sua categoria, ou seja, apenas relevante. Por conta disso, com uma base de dados maior, em que muitas palavras novas apareceriam e se repetiriam, o classificador poderia aprimorar suas probabilidades, aumentando o numero de acertos ainda mais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Falsos positivos e falsos negativos, são as duas categorias que mais afetam uma empresa, visto que no primeiro caso, o classificador acaba classificando algo relevante como irrelevante, e no segundo, o mesmo acerta tal classificação. Para tais categorias, respectivamente, as porcentagens são de 10.5% e 10.5% (soma de muito relevante com relevantes). Portanto, a porcentagem é igual em ambos, mostrando que há uma chance igual de erro e de acerto quando se trata de tweets relevantes, o que tambem é fruto do baixo número de tweets apanhados. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No caso de dupla negação ou sarcasmo, como muitos tweets deste tipo eram retweets, o classificador acabou colocando-os no lugar certo, na maioria das vezes. Para aqueles tweets que contém dupla negação e não foram anteriormente apresentados para o classificador, a probabilidade de uma palavra negativa acompanhada de outra acabam se sobrepondo as demais, classificando o mesmo muitas vezes no lugar errado. Além disso, o classificador não é capaz de captar sarcasmos ou ironias, por considerar apenas a probabilidade de palavras separadas, como se as mesmas fossem independentes, levando-o a marcar as frases em outra categoria. Outro ponto, consiste no fato de que, aqueles tweets que contém adjetivos e palavras com probabilidades altíssimas, acabam levando o classificador a escolher uma categoria que não foi aquela anteriormente apresentada por nós."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em um ambiente empresarial, um dos fatores que mais impacta nas vendas e projetos de produtos, é o usuário. Com o classificador desenvolvido, é possível com facilidade filtrar aqueles comentários que devem ser analisados pela empresa, para que a mesma possa realizar seus projetos com base no conteúdo apresentado nos tweets que o classificador julgou relevante, sem ter de faze-lo manualmente. Para aprimorar o percentual de acerto, é necessário aumentar a base de Treinamento, o que o tornaria uma forte ferramenta de controle de satisfação. Além disso, em uma futura iteração, o classificador poderia ser utilizado para analisar diferentes produtos ao mesmo tempo, o que daria uma noção geral de como está a reputação da empresa juntamente com seu produto. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O classficador não poderia ser utilizado em tweets novos, muito menos quando um novo produto é lançado no mercado pela empresa. O fato ocorre pois o mesmo contém apenas as probabilidades das palavras que estão fazendo parte da discussão do twitter em certo dia, e como é impossivel saber se surgirá uma nova hashtag ou termo, o classificador não pode ser utilizado, já que a probabilidade da mesma (hashtag, palavra) seria baixa, pois sua frequencia na base de treinamento eh zero, já que a base esta destualizada. No caso de um lançamento de um novo produto, do mesmo modo que foi citado anteriormete, o classificador não dará uma probabilidade alta de relevância por conta da frequencia do termo ser nula na base de treinamento. Para solucionar tal problema, seria necessário atualizar a base de treinamento toda a vez que algo relevante tomar conta das discussões do twitter, para assim o classificador poder operar de forma correta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O classificador Naive Bayes, tem várias outras vertentes aplicadas no dia a dia. Uma delas é o papel na medicina, já que a probabilidade de uma pessoa ter uma certa doença, é calculada pela probabilidade da mesma ter a doença, dado que sua família a teve ou dado que 100 mil habitantes de uma certa cidade tambem tiveram. Podemos citar como um exemplo o cancer, em que o papel da familia é crucial para o calculo da probabilidade de o filho ter a doença.\n",
    "Além disso, pode-se prever por exemplo, a probabilidade de acontecer certo desastre natural dado que a localização escolhida tem certo historico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a melhoria do classificador, uma base de treinamento de no mínimo 1000 tweets seria necessária, já que mais palavras seriam\n",
    "registradas no dicionário de probabilidades, o que forneceria uma melhor base para o classificador trabalhar. Com o aumento dos tweets, as categorias não muito comuns, como muito relevante, seriam melhor preenchidas, melhorando assim, a porcentagem de acerto da mesma, a qual se refere a uma das mais importantes a serem analisadas em uma empresa. Com o intuito de melhorar o duplo sentido, negação e sarcasmo dos tweets, uma lista de palavras poderia ser criada com suas probabilidades, de forma que o conteúdo da mesma contenha apenas os termos que compõem um tweet que foi classificdo como ironico, de maneira que ao calcular todas as probabilidades, o classificador mudará o tweet de categoria caso ele tenha uma alta probabilidade de ter duplo sentido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
